{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "502ff518",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [7]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fe4a709",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T12:38:39.582655Z",
     "iopub.status.busy": "2023-02-16T12:38:39.582104Z",
     "iopub.status.idle": "2023-02-16T12:38:39.588884Z",
     "shell.execute_reply": "2023-02-16T12:38:39.588449Z"
    },
    "papermill": {
     "duration": 0.050211,
     "end_time": "2023-02-16T12:38:39.589904",
     "exception": false,
     "start_time": "2023-02-16T12:38:39.539693",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "input_files = {}\n",
    "distribution_parameters = {}\n",
    "#WARNING: When re-running the notebook for audit, change the injected path below to \"./output_praiseDist_test.ipynb\"\n",
    "#then go to \"Cell > Run all\" -- This only works for the notebook in \n",
    "#\"distribution_results/round ?/results/analysis_outputs/output_general_RAD_report.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e90ba41d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T12:38:39.630004Z",
     "iopub.status.busy": "2023-02-16T12:38:39.629450Z",
     "iopub.status.idle": "2023-02-16T12:38:39.633562Z",
     "shell.execute_reply": "2023-02-16T12:38:39.633207Z"
    },
    "papermill": {
     "duration": 0.023139,
     "end_time": "2023-02-16T12:38:39.634391",
     "exception": false,
     "start_time": "2023-02-16T12:38:39.611252",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "dist_notebook_path = \"/data/round-1/distribution_results/executed_notebooks/output_praiseDistribution.ipynb\"\n",
    "input_files = {\n",
    "    \"praise_data\": \"/data/round-1/praise.csv\",\n",
    "    \"rewardboard_list\": \"/data/round-1/rewardboard.csv\",\n",
    "    \"cross_period_root\": \"/data\",\n",
    "}\n",
    "distribution_parameters = {\n",
    "    \"input_files\": {\n",
    "        \"praise_data\": \"/data/round-1/praise.csv\",\n",
    "        \"rewardboard_list\": \"/data/round-1/rewardboard.csv\",\n",
    "        \"cross_period_root\": \"/data\",\n",
    "    },\n",
    "    \"payout_token\": {\n",
    "        \"token_name\": \"GIV\",\n",
    "        \"token_address\": \"0x4f4F9b8D5B4d0Dc10506e5551B0513B61fD59e75\",\n",
    "    },\n",
    "    \"token_reward_percentages\": {\n",
    "        \"contributor_rewards\": 0.9,\n",
    "        \"quantifier_rewards\": 0.07,\n",
    "        \"rewardboard_rewards\": 0.03,\n",
    "        \"ceiling_cutoff\": 1500,\n",
    "    },\n",
    "    \"quantification_settings\": {\n",
    "        \"number_of_quantifiers_per_praise_receiver\": 3,\n",
    "        \"praise_quantify_allowed_values\": [0, 1, 3, 5, 8, 13, 21, 34, 55, 89, 144],\n",
    "        \"praise_quantify_receiver_pseudonyms\": False,\n",
    "        \"praise_quantify_duplicate_praise_valuation\": 0.1,\n",
    "    },\n",
    "    \"cross_period_settings\": {\"cross_period_week_num\": 52, \"cross_period_step_size\": 2},\n",
    "    \"total_tokens_allocated\": \"58000\",\n",
    "    \"distribution_name\": \"round-27\",\n",
    "    \"results_output_folder\": \"distribution_results\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "677d3b44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T12:38:39.669490Z",
     "iopub.status.busy": "2023-02-16T12:38:39.669357Z",
     "iopub.status.idle": "2023-02-16T12:38:39.671979Z",
     "shell.execute_reply": "2023-02-16T12:38:39.671672Z"
    },
    "papermill": {
     "duration": 0.021027,
     "end_time": "2023-02-16T12:38:39.672885",
     "exception": false,
     "start_time": "2023-02-16T12:38:39.651858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    categ_keywords = distribution_parameters['categorization_settings']['type_keywords']\n",
    "except:\n",
    "    #categ_keywords = {'attendance':'join|attend|show up|participat','discussion':'question|ask|discuss|discussion','work':'help|work|design|make|write|hack|edit','lead':'host|lead|initiate|form|organize|steward','share':'share|spread','twitter':'twitter|tweet','hack':'hack|test','general':'support|awesome','IRL':'trip|conference'}\n",
    "    categ_keywords = {'attendance':'join|attend|show up|coming to','discussion':'question|ask|discuss|discussion|insight|participat|feedback|observations|forum|comment|share','work':'work|writing|hack|edit|studying|research|drafting|mediat|recording|taking notes|note taking|develop|analysis','lead':'host|lead|initiat|organizing|organizer|steward|forming|facilitate|managing','share':'share|spread','social media':'twitter|tweet|retweet|socials|social media','hardskills':'design|bug fixes|deploy|prototype|coding|python|javascript|solidity|data science','self-care':'vacation|time off|time-off|holiday|sabbatical|day off','IRL':'trip|DAOist|ETHcc|barcelona|denver|paris|amsterdam|colombia'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5b95fea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T12:38:39.706342Z",
     "iopub.status.busy": "2023-02-16T12:38:39.706231Z",
     "iopub.status.idle": "2023-02-16T12:38:39.708910Z",
     "shell.execute_reply": "2023-02-16T12:38:39.708442Z"
    },
    "papermill": {
     "duration": 0.020387,
     "end_time": "2023-02-16T12:38:39.709777",
     "exception": false,
     "start_time": "2023-02-16T12:38:39.689390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    NUMBER_OF_WEEKS = distribution_parameters[\"cross_period_settings\"][\"cross_period_week_num\"]\n",
    "    STEP_SIZE = distribution_parameters[\"cross_period_settings\"][\"cross_period_step_size\"]\n",
    "except:\n",
    "    NUMBER_OF_WEEKS = 4\n",
    "    STEP_SIZE = 1\n",
    "    print(f'Using default time period: the most recent {NUMBER_OF_WEEKS} weeks, looking into every {STEP_SIZE} week.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2546bfec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T12:38:39.745444Z",
     "iopub.status.busy": "2023-02-16T12:38:39.745000Z",
     "iopub.status.idle": "2023-02-16T12:38:46.606775Z",
     "shell.execute_reply": "2023-02-16T12:38:46.605576Z"
    },
    "papermill": {
     "duration": 6.88259,
     "end_time": "2023-02-16T12:38:46.609187",
     "exception": false,
     "start_time": "2023-02-16T12:38:39.726597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from collections import OrderedDict\n",
    "from natsort import natsorted\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "from IPython.display import Markdown as md\n",
    "\n",
    "import scrapbook as sb\n",
    "\n",
    "from re import search\n",
    "\n",
    "#adding directories for the analysis tool. this is mainly for when we re-run the notebook \n",
    "dir2 = os.path.abspath('../../../../../rad/analysis_tools')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: sys.path.append(dir1)\n",
    "from analysis_tools.module_libraries import praise_analysis_module as praise_tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8bc18fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T12:38:46.658487Z",
     "iopub.status.busy": "2023-02-16T12:38:46.658359Z",
     "iopub.status.idle": "2023-02-16T12:38:46.664151Z",
     "shell.execute_reply": "2023-02-16T12:38:46.663824Z"
    },
    "papermill": {
     "duration": 0.026223,
     "end_time": "2023-02-16T12:38:46.665059",
     "exception": false,
     "start_time": "2023-02-16T12:38:46.638836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_into_weeks(data, num_weeks, step_size):\n",
    "    data = data.sort_values(by='DATE', ascending = True).reset_index()\n",
    "    data[\"DATE\"] = pd.to_datetime(data[\"DATE\"])\n",
    "    \n",
    "    first_date = pd.to_datetime(data.at[len(data.index) - 1, \"DATE\"]) - timedelta(weeks=(num_weeks))\n",
    "    \n",
    "    roundname_list = []\n",
    "\n",
    "    rounds_df = {}\n",
    "    for week in range(0, num_weeks, step_size):\n",
    "        week_id = \"Week \" + str(week+1)\n",
    "        roundname_list.append(week_id)\n",
    "        rounds_df[week_id]= []\n",
    "        start_date = first_date + timedelta(weeks=(week))\n",
    "        end_date = first_date + timedelta(weeks=(week+step_size))\n",
    "        \n",
    "        rounds_df[week_id] =  data.loc[(data['DATE'] >= start_date) & (data['DATE'] <= end_date)]\n",
    "\n",
    "                \n",
    "    return rounds_df, roundname_list\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9238ee9",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c838ec1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T12:38:46.703851Z",
     "iopub.status.busy": "2023-02-16T12:38:46.703407Z",
     "iopub.status.idle": "2023-02-16T12:38:47.450262Z",
     "shell.execute_reply": "2023-02-16T12:38:47.449679Z"
    },
    "papermill": {
     "duration": 0.769063,
     "end_time": "2023-02-16T12:38:47.451105",
     "exception": true,
     "start_time": "2023-02-16T12:38:46.682042",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/round-2/distribution_results/raw_csv_exports/praise_outliers.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     12\u001b[0m rounds\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 13\u001b[0m round_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdatadir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mround_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/distribution_results/raw_csv_exports/praise_outliers.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m dist_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatadir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mround_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/distribution_results/raw_csv_exports/extended_praise_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m round_df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m#print(row)\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/parsers/readers.py:586\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    571\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    572\u001b[0m     dialect,\n\u001b[1;32m    573\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    583\u001b[0m )\n\u001b[1;32m    584\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/parsers/readers.py:482\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    479\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    481\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 482\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/parsers/readers.py:811\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwds:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 811\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1040\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1037\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown engine: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (valid options are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmapping\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1038\u001b[0m     )\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;66;03m# error: Too many arguments for \"ParserBase\"\u001b[39;00m\n\u001b[0;32m-> 1040\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py:51\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     48\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musecols\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musecols\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# open handles\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open_handles\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Have to pass int, would break tests using TextReader directly otherwise :(\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py:222\u001b[0m, in \u001b[0;36mParserBase._open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_handles\u001b[39m(\u001b[38;5;28mself\u001b[39m, src: FilePathOrBuffer, kwds: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m    Let the readers open IOHandles after they are done with their potential raises.\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 222\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/common.py:702\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    701\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 702\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    710\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    711\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/round-2/distribution_results/raw_csv_exports/praise_outliers.csv'"
     ]
    }
   ],
   "source": [
    "datadir = input_files[\"cross_period_root\"]\n",
    "foldername_list = natsorted(os.listdir(datadir))\n",
    "\n",
    "allrounds_df = []\n",
    "allrounds_finaldist = []\n",
    "\n",
    "rounds = 0\n",
    "for round_name in foldername_list:\n",
    "    if not os.path.isdir(f'{datadir}/{round_name}'):\n",
    "        foldername_list.remove(round_name)\n",
    "        continue\n",
    "    rounds+=1\n",
    "    round_df = pd.read_csv(f'{datadir}/{round_name}/distribution_results/raw_csv_exports/praise_outliers.csv')\n",
    "    dist_df = pd.read_csv(f'{datadir}/{round_name}/distribution_results/raw_csv_exports/extended_praise_data.csv')\n",
    "\n",
    "    \n",
    "    for index, row in round_df.iterrows():\n",
    "        #print(row)\n",
    "        row['QUANT ROUND']=round_name\n",
    "        allrounds_df.append(row)\n",
    "    for index, row in dist_df.iterrows():\n",
    "        row['QUANT_ROUND']=round_name\n",
    "        allrounds_finaldist.append(row)\n",
    "        \n",
    "    \n",
    "allrounds_df = pd.DataFrame(allrounds_df)\n",
    "allrounds_finaldist = pd.DataFrame(allrounds_finaldist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf13e5b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "allrounds_df.drop(\"index\", axis =1,  inplace=True)\n",
    "allrounds_df.fillna(value={\"QUANTIFIER 4 USERNAME\": \"None\"}, inplace=True)\n",
    "master_allrounds = allrounds_df.copy()\n",
    "week_df, roundname_list = split_into_weeks(allrounds_df, NUMBER_OF_WEEKS, STEP_SIZE)\n",
    "allrounds_df = week_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fef1112",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "finaldist_weekly, roundname_list = split_into_weeks(allrounds_finaldist, NUMBER_OF_WEEKS, STEP_SIZE)\n",
    "for period in roundname_list:\n",
    "\n",
    "    period_dist = finaldist_weekly[period].copy()\n",
    "    period_dist = period_dist[['TO USER ACCOUNT ID', 'DATE', 'TO USER ACCOUNT', 'TOKEN TO RECEIVE']].copy().groupby(['TO USER ACCOUNT ID', 'TO USER ACCOUNT',]).agg('sum').reset_index()\n",
    "    period_dist.rename(columns = {'TOKEN TO RECEIVE': 'PRAISE REWARDS'}, inplace = True)\n",
    "    \n",
    "    period_dist = period_dist.sort_values(by='PRAISE REWARDS', ascending=False).reset_index()\n",
    "    period_dist.drop(\"index\", axis =1,  inplace=True)\n",
    "    \n",
    "    finaldist_weekly[period] = period_dist\n",
    "    \n",
    "allrounds_finaldist = finaldist_weekly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326ca887",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Cross-Period Analysis Report\n",
    "This report aims to offer a perspective on the activity inside the praise system over several rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61409884",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "md(f\"This report will cover <b>{NUMBER_OF_WEEKS}</b> weeks, divided into blocks of <b>{STEP_SIZE}</b> weeks each.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60167805",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# General Statistics\n",
    "The full range will be subdivided into the following periods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0896c63",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "round_stats = pd.DataFrame(index=allrounds_df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308a3681",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "round_stats['period_start_time'] =  [str(allrounds_df[round_name]['DATE'].min())[:10] for round_name in roundname_list]\n",
    "round_stats['period_end_time'] =  [str(allrounds_df[round_name]['DATE'].max())[:10] for round_name in roundname_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18bc3d7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "round_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be6baf2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Praise Involvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822d322d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### How much praise? \n",
    "This graph shows the trend of total number of praise instances across time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e24a823",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "round_stats['total_praise'] = [len(allrounds_df[round_name]) for round_name in roundname_list]\n",
    "px.line(round_stats,x='period_start_time',y='total_praise',markers=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eef7b85",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### How many people give and receive praise?\n",
    "Counting the unique ID of praise givers and receivers, we can visualize the change across time. In the figure, the blue line represents the amount of praise receivers and thered line the amount of givers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c0a647",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "round_stats['total_praise_receiver'] = [len(np.unique(allrounds_df[round_name]['TO USER ACCOUNT'])) for round_name in roundname_list]\n",
    "round_stats['total_praise_giver'] = [len(np.unique(allrounds_df[round_name]['FROM USER ACCOUNT'])) for round_name in roundname_list]\n",
    "\n",
    "px.line(round_stats,x='period_start_time',y=['total_praise_receiver','total_praise_giver'],markers=True,title='total praise giver and receiver')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4ca3a0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Quantifier Involvement\n",
    "Showing how many quantifiers are involved in each round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eacac2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#this metric has to be kept in a per-round basis, since quntifiers are assigned in that rythm\n",
    "try:\n",
    "    quant_stats = pd.DataFrame()\n",
    "    quant_stats[\"quant_round\"] = foldername_list\n",
    "    quant_stats['total_quantifier'] = [len(np.unique(master_allrounds[master_allrounds['QUANT ROUND'] == round_name].filter(like='QUANTIFIER'))) for round_name in foldername_list]\n",
    "    px.line(quant_stats,x=\"quant_round\",y=['total_quantifier'],markers=True,title='total quantifiers')\n",
    "except:\n",
    "    print(\"Exception encountered while processing quantifiers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148db817",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Quantifier trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d19bfe",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    pr=praise_tools.praise_quantifier(master_allrounds)\n",
    "except:\n",
    "    print(\"Exception encountered while processing quantifiers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4ae456",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### average score displacement: tendency to under/over-estimate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec886aa7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    pr.plot_mean_displacement()\n",
    "except:\n",
    "    print(\"Exception encountered while processing quantifiers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36527731",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### average score correlation coefficient: how much do i agree with other people?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8121c07",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    pr.plot_coefficient()\n",
    "except:\n",
    "    print(\"Exception encountered while processing quantifiers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd05bfc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# System Health Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526f8477",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "\n",
    "## Number of new TEC members involved in praise (either giving or receiving)\n",
    "Counting the round-by-round change of unique IDs being either praise giver or praise receiver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef93ad3b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    round_stats['round_user_list'] = [set(np.unique(allrounds_df[round_name].filter(like='ACCOUNT')))\n",
    "            .union(set(np.unique(allrounds_df[round_name].filter(like='QUANTIFIER')))) for round_name in roundname_list]\n",
    "except:\n",
    "    print(\"Error in quantifiers, skipping them for analysis\")\n",
    "    round_stats['round_user_list'] = [set(np.unique(allrounds_df[round_name].filter(like='ACCOUNT'))) for round_name in roundname_list]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52ab3fc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "round_stats['round_user_new'] = [np.nan]+ [len(round_stats.loc[roundname_list[kr+1],'round_user_list'] - \n",
    "                                         round_stats.loc[roundname_list[kr],'round_user_list']) for kr in np.arange(len(roundname_list)-1)]\n",
    "\n",
    "round_stats['round_user_left'] = [np.nan]+[len(round_stats.loc[roundname_list[kr],'round_user_list'] - \n",
    "                                         round_stats.loc[roundname_list[kr+1],'round_user_list']) for kr in np.arange(len(roundname_list)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d713bd21",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "round_stats['round_net_user_diff']=round_stats['round_user_new']-round_stats['round_user_left']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60e4c03",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "The blue line represents new IDs in this round, the red line represents IDs that are absent in this round but were present in the last round. The green line shows the net difference, with above 0 meaning more people joined praise than people left and below 0 meaning the opposite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a688024",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "px.line(round_stats,x='period_start_time',y=['round_user_new','round_user_left','round_net_user_diff'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6e2a29",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Distribution Equality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699f3461",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Nakamoto Coefficient\n",
    "\n",
    "The Nakamato Coefficient is defined as the smallest number of accounts who control at least 50% of the resource. Although its significance relates to the prospect of a 51% attack on a network, which may not be relevant in our context, we can still use it as an intuitive measure of how many individuals received the majority of rewards.\n",
    "\n",
    "Bigger coefficient means more distributed (i.e. needs more people to pass 50%), smaller means more concentrated power. The number should always be an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50215949",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def nakamoto_coeff(x, key):\n",
    "    value_sum= x[key].sum()\n",
    "    x['PERCENTAGE'] = x[key] / value_sum\n",
    "    sorted_x = x.sort_values(by='PERCENTAGE', ascending=False)\n",
    "    tot_sum = np.array(sorted_x['PERCENTAGE'].cumsum())\n",
    "    try:\n",
    "        winner = np.array([k for k in range(len(tot_sum))\n",
    "                          if tot_sum[k] > 0.5]).min() + 1\n",
    "    except:\n",
    "        winner = -1\n",
    "    return winner\n",
    "def nakamoto_coeff_ratio(x, key):\n",
    "    winner = nakamoto_coeff(x, key)\n",
    "    ratio = winner / len(x)\n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a754f44",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "round_stats['nakamoto']  = [nakamoto_coeff(allrounds_finaldist[round_name],'PRAISE REWARDS') for round_name in roundname_list]\n",
    "round_stats['nakamoto_ratio']= [nakamoto_coeff_ratio(allrounds_finaldist[round_name],'PRAISE REWARDS') for round_name in roundname_list]\n",
    "px.line(round_stats,x='period_start_time',y='nakamoto',markers=True,title='Minimum number of people receiving 50% of total rewards')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c5e204",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "px.line(round_stats,x='period_start_time',y='nakamoto_ratio',markers=True,title='Ratio of people accumulating 50% of total rewards in relation to total number of receivers in that round')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9071942b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Categorizing praise based on the praise reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215d7590",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def categorize_praise(master_df,categ_keywords,save_csv=False):\n",
    "    # clean the data\n",
    "    allpraise_df = master_df[['REASON','AVG SCORE','TO USER ACCOUNT','DATE']]\n",
    "    nonzerodf = allpraise_df.loc[(allpraise_df['AVG SCORE']>0) * (~allpraise_df['REASON'].isnull())]\n",
    "    #print(f'among {len(allpraise_df)} praises, {len(nonzerodf)} have scores more than 0. Only include them')\n",
    "    nonzerodf.insert(0,'CLEANED REASON',nonzerodf['REASON'].apply(praise_tools.clean_praise))\n",
    "\n",
    "    # do categorization\n",
    "    allcategs = []\n",
    "    for kr,row in nonzerodf.iterrows():\n",
    "        category = []\n",
    "        praise = row['CLEANED REASON'].lower()\n",
    "        for praise_type,keywords in categ_keywords.items():\n",
    "            if search(keywords,praise):\n",
    "                category.append(praise_type)\n",
    "        if len(category):\n",
    "            allcategs.append(category)\n",
    "        else:\n",
    "            allcategs.append(np.nan)\n",
    "    category_df = pd.concat([nonzerodf.reset_index(), pd.DataFrame({\"category\":allcategs})],axis=1)\n",
    "    if save_csv:\n",
    "        # save the categorization into csv; there's a file including only uncategorized praise\n",
    "        category_df.loc[category_df['category'].isnull()].to_csv('uncateogrized.csv')\n",
    "        print(f\"{sum(category_df['category'].isnull())} out of {len(category_df)} praises uncategorized\")\n",
    "        category_df.to_csv('categorized_praise.csv')\n",
    "    \n",
    "    #When there's a praise matching more than one category, they will be counted multiple times\n",
    "    #organize the data for easier analysis\n",
    "    categ_praise_scores = {k:[] for k in categ_keywords.keys()}\n",
    "\n",
    "    for kr,row in category_df.iterrows():\n",
    "        if type(row['category']) is list:\n",
    "            for key in row['category']:\n",
    "                categ_praise_scores[key] += [{'praise':row['REASON'],'avg_score':row['AVG SCORE'],'receiver':row['TO USER ACCOUNT'],'date':row['DATE']}]\n",
    "    categ_praise_scores_df = dict.fromkeys(categ_keywords.keys())\n",
    "    for key, item in categ_praise_scores.items():\n",
    "        categ_praise_scores_df[key]= pd.DataFrame(item)\n",
    "    return categ_praise_scores_df,category_df\n",
    "def get_categ_stats(df,keywords):\n",
    "    categ_stats = dict.fromkeys(keywords.keys())\n",
    "    for categ in keywords.keys():\n",
    "        if len(df[categ])==0: # empty category, skip this\n",
    "            continue\n",
    "        categ_stats[categ] = {'mean':np.mean(df[categ]['avg_score']),\n",
    "                                'max':np.max(df[categ]['avg_score']),\n",
    "                                'min':np.min(df[categ]['avg_score'])}\n",
    "        \n",
    "    categ_stats_df = pd.DataFrame(categ_stats)\n",
    "    categ_stats_df = categ_stats_df.transpose().sort_values(by='mean')\n",
    "    return categ_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3277c78f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "categ_praise_df,category_df = categorize_praise(master_allrounds,categ_keywords,save_csv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d4b99a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "##  the average, min, max score of each category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c6dbbc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "categ_stats = get_categ_stats(categ_praise_df,categ_keywords)\n",
    "categ_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6585784",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot it out\n",
    "categ_stats = get_categ_stats(categ_praise_df,categ_keywords)\n",
    "categ_stats['max-mean'] = categ_stats['max'] - categ_stats['mean']\n",
    "categ_stats['mean-min'] = categ_stats['mean'] - categ_stats['min']\n",
    "\n",
    "fig=px.bar(categ_stats,y='mean',error_y='max-mean',error_y_minus='mean-min',title='average score of each category')\n",
    "fig.show()\n",
    "md('errorbars mark the maximum average score for this category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e850a9cd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Top 3 highest scored praise in each category\n",
    "A convenient way to check if the categorization keywords are reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea8ccfa",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mdtext = ''\n",
    "for categ in categ_praise_df.keys():\n",
    "    categ_name = '# '+categ + '\\n'\n",
    "    toppraise = categ_praise_df[categ].sort_values(by='avg_score',ascending=False).iloc[:3]\n",
    "    top3_table= (f\"\\\n",
    "| Avg. score | To | Reason | Date |\\n \\\n",
    "|:-----------|----|--------|-----:|\\n\")\n",
    "    for kr,row in toppraise.iterrows():\n",
    "        to_user = row['receiver']\n",
    "        reason = row['praise']\n",
    "        score = row['avg_score']\n",
    "        date = row['date'][:10]\n",
    "                    \n",
    "        top3_table += (f\"| {score} | {to_user} | {reason} | {date} |\\n\")\n",
    "        #print(f'Praise score average: {score}\\nFROM {from_user} TO {to_user},reason:\\n{reason}\\n')\n",
    "    mdtext += categ_name + top3_table    \n",
    "md(mdtext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30deb699",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## trend across time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba09b1d0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_score_dict = {k:[] for k in categ_keywords.keys()}\n",
    "praise_num_dict = {k:[] for k in categ_keywords.keys()}\n",
    "for round_name in roundname_list:\n",
    "    round_categ_praise_score_df,_ = categorize_praise(allrounds_df[round_name],categ_keywords)\n",
    "    round_categ_stats = get_categ_stats(round_categ_praise_score_df,categ_keywords)\n",
    "    for key in mean_score_dict.keys():\n",
    "        try:\n",
    "            mean_score_dict[key].append(float(round_categ_stats['mean'].loc[key]))\n",
    "        except: \n",
    "            mean_score_dict[key].append(0.0)\n",
    "        praise_num_dict[key].append(len(round_categ_praise_score_df[key]))\n",
    "for key in mean_score_dict.keys():  \n",
    "    round_stats[key+'_avg_score']=mean_score_dict[key]\n",
    "    round_stats[key+'_praise_num']=praise_num_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86244914",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "px.line(round_stats.filter(like='num'),title='number of praise in each category, across time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a4fd3c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "px.line(round_stats.filter(like='_avg_score'),title='mean score of each category, across time')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9.22707,
   "end_time": "2023-02-16T12:38:47.995621",
   "environment_variables": {},
   "exception": true,
   "input_path": "./analysis_tools/notebooks/praise/02-cross-period-analysis.ipynb",
   "output_path": "/data/round-1/distribution_results/executed_notebooks/output_02-cross-period-analysis.ipynb",
   "parameters": {
    "dist_notebook_path": "/data/round-1/distribution_results/executed_notebooks/output_praiseDistribution.ipynb",
    "distribution_parameters": {
     "cross_period_settings": {
      "cross_period_step_size": 2,
      "cross_period_week_num": 52
     },
     "distribution_name": "round-27",
     "input_files": {
      "cross_period_root": "/data",
      "praise_data": "/data/round-1/praise.csv",
      "rewardboard_list": "/data/round-1/rewardboard.csv"
     },
     "payout_token": {
      "token_address": "0x4f4F9b8D5B4d0Dc10506e5551B0513B61fD59e75",
      "token_name": "GIV"
     },
     "quantification_settings": {
      "number_of_quantifiers_per_praise_receiver": 3,
      "praise_quantify_allowed_values": [
       0,
       1,
       3,
       5,
       8,
       13,
       21,
       34,
       55,
       89,
       144
      ],
      "praise_quantify_duplicate_praise_valuation": 0.1,
      "praise_quantify_receiver_pseudonyms": false
     },
     "results_output_folder": "distribution_results",
     "token_reward_percentages": {
      "ceiling_cutoff": 1500,
      "contributor_rewards": 0.9,
      "quantifier_rewards": 0.07,
      "rewardboard_rewards": 0.03
     },
     "total_tokens_allocated": "58000"
    },
    "input_files": {
     "cross_period_root": "/data",
     "praise_data": "/data/round-1/praise.csv",
     "rewardboard_list": "/data/round-1/rewardboard.csv"
    }
   },
   "start_time": "2023-02-16T12:38:38.768551",
   "version": "2.3.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}